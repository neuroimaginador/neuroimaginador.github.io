---
title: Automatic Model Selection for Probabilistic {PCA}
date: '2007-01-01'
authors:
- E. López-Rubio
- J.M. Ortiz-De-Lazcano-Lobato
- admin
- M. Del Carmen Vargas-González
publication_types: 
- '1'
publication: Lecture Notes in Computer Science (including subseries Lecture Notes
  in Artificial Intelligence and Lecture Notes in Bioinformatics), (4507 LNCS), _pp.
  127-134_
publication_short: ''
doi: 10.1007/978-3-540-73007-1_16
abstract: The Mixture of Probabilistic Principal Components Analyzers (MPPCA) is a
  multivariate analysis technique which defines a Gaussian probabilistic model at
  each unit. The number of units and principal directions in each unit is not learned
  in the original approach. Variational Bayesian approaches have been proposed for
  this purpose, which rely on assumptions on the input distribution and/or approximations
  of certain statistics. Here we present a different way to solve this problem, where
  cross-validation is used to guide the search for an optimal model selection. This
  allows to learn the model architecture without the need of any assumptions other
  than those of the basic PPCA framework. Experimental results are presented, which
  show the probability density estimation capabilities of the proposal with high dimensional
  data. © Springer-Verlag Berlin Heidelberg 2007.
math: yes
highlight: yes
header:
  image: ''
  caption: ''
links:
- name: Download PDF
  url: publication/2007-01-01_automatic_model_sele/paper.pdf
url_pdf: ''
projects: ''
selected: no
url_slides: ''
image_preview: ''
tags:
- Approximation theory
- Bayesian networks
- Gaussian distribution
- Mathematical models
- Probability density function
- Multivariate analysis
- Optimal model selection
- Principal component analysis
---
